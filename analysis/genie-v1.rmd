---
title: Genie Game Results — Final
date: "`r Sys.Date()`"
author: "fredcallaway"
output:
  rmdformats::robobook:
    code_folding: hide
    self_contained: true
---


```{r setup, include=FALSE}
source("base.r")
library(moments)
library(scales)
library(infer)

VERSIONS = c('v1.2B', 'v1.2C')
load_data = function(type) {
    VERSIONS %>% 
    map(~ read_csv(glue('../data/{.x}/{type}.csv'), col_types = cols())) %>% 
    bind_rows
}

considered_colors = scale_colour_manual(values=c(
    "#3DD93D",
    "#666666"
), aesthetics=c("fill", "colour"), name="")

control_colors = scale_colour_manual(values=c(
    "#31ADF4",
    "#F5CE47"
), aesthetics=c("fill", "colour"))

```

# Exclusions

```{r load_data}
full_pdf = load_data('participants') %>% 
    filter(completed) %>% 
    select(-c(consideration_time, reflection_time, n_considered, n_unconsidered, version, bonus, completed)) %>%
    mutate(
        obligatory_check = factor(if_else(comp_radio, 'incorrect', 'correct', 'empty'),
                                  levels=c('empty', 'incorrect', 'correct')),
    )

full_df = load_data('evaluation') %>% 
    rename(scenario = prompt_id) %>% 
    mutate(scenario = tolower(scenario))

full_consideration = load_data('consideration') %>% 
    rename(scenario = prompt_id) %>% 
    mutate(scenario = tolower(scenario))

full_slider = load_data('slider_check')

slider_check = full_slider %>% 
    mutate(prompt = word(prompt)) %>% 
    pivot_wider(names_from=prompt, values_from=response) %>% 
    mutate(
        p1 = Breaking < Stubbing,
        p2 = Stubbing < Finding,
        p3 = Finding < Winning,
        pass = p1 & p2 & p3
    )

# slider_check %>% summarise(across(-wid, mean))

# table(full_pdf$obligatory_check)
pdf = full_pdf %>% 
    filter(obligatory_check == "correct") %>% 
    left_join(slider_check) %>% 
    filter(pass) %>% 
    mutate(
        control = factor(control, levels=c("low", "high"))
    )

pdf2 = select(pdf, wid, control)

consideration = full_consideration %>%
    right_join(pdf2)  %>% 
    filter(scenario != "practice") %>%
    filter(outcome %nin% c("NONE", "UNK")) %>% 
    select(-raw_outcome) %>% 
    group_by(wid, scenario) %>% 
    mutate(order = row_number())

df = full_df %>% 
    right_join(pdf2) %>% 
    filter(scenario != "practice") %>% 
    left_join(transmute(consideration, wid, scenario, outcome, order, considered=T)) %>% 
    replace_na(list(considered=F)) %>% 
    group_by(wid) %>% 
    mutate(
        evaluation_z = zscore(evaluation),
        abs_eval = abs(evaluation),
        abs_eval_z = zscore(abs_eval),
    ) %>% 
    ungroup()

acc = read_csv('../data/acc-v2.0/accessibility.csv', col_types = cols())

acc %>% 
    filter(cat_id != "EUROCITIES") %>%
    filter(outcome != "UNK") %>%
    count(outcome) %>% 
    mutate(accessibility = n / length(unique(acc$wid))) %>% 
    select(-n) %>% 
    right_join(df) -> df


df = filter(df, !is.na(accessibility))

# stopifnot(df %>% group_by(wid, scenario) %>% filter(sum(considered)!=1) %>% nrow == 0)
stopifnot(df %>% filter(is.na(accessibility)) %>% nrow == 0)

df %>% 
    arrange(wid, scenario, order) %>% 
    write_csv("../data/processed.csv")
```

- `r nrow(full_pdf)` participants recruited.
- `r sum(full_pdf$obligatory_check != "correct")` failed the comprehension check.
- `r sum(!slider_check$pass)` participants failed the slider check.
- `r nrow(pdf)` passed both checks and are included in the analysis.



# Proportion of good/bad/neutral

```{r}
ebins = df %>% 
    group_by(evaluation) %>% 
    filter(!is.na(accessibility)) %>% 
    summarise(acc=sum(accessibility)) %>% 
    mutate(prop=acc/sum(acc)) %>% 
    mutate(ebin=cut(cumsum(prop), c(0, 1/3, 2/3, 1.01), labels=c("bad", "neutral", "good"))) %>% 
    select(evaluation, ebin) 

df %>% 
    left_join(ebins) %>% 
    filter(considered)  %>% 
    ggplot(aes(ebin, y=..prop.., group=control,fill=control)) + 
    geom_bar(position="dodge", alpha=0.7) +
    geom_hline(yintercept=1/3, linetype="solid") +
    control_colors +
    labs(x="value bin", y="proportion of considered outcomes")
```

## Tests

```{r}
baselines = df %>%
    filter(!is.na(accessibility)) %>% 
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

X = baselines %>% 
    mutate(ebin=cut(cumsum(prop), c(0, 1/3, 2/3, 1.01), labels=c("bad", "neutral", "good"))) %>% 
    select(evaluation, ebin) %>% 
    right_join(df) %>% 
    filter(considered) %>%
    count(control, ebin) %>% 
    pivot_wider(names_from=ebin, values_from=n) %>%
    mutate(total=bad+neutral+good)

low =  X %>% filter(control=="low")
high = X %>% filter(control=="high")

cat(
    "\n\nlow-control good > chance:",
    pval(prop.test(low$good, low$total, 1/3, 'greater')$p.value),
    "\n\nlow-control bad > chance:",
    pval(prop.test(low$bad, low$total, 1/3, 'greater')$p.value),
    "\n\nlow-control neutral < chance:",
    pval(prop.test(low$neutral, low$total, 1/3, 'less')$p.value),
    "\n\nhigh-control good > chance:",
    pval(prop.test(high$good, high$total, 1/3, 'greater')$p.value),
    "\n\nhigh-control bad > chance:",
    pval(prop.test(high$bad, high$total, 1/3, 'less')$p.value),
    "\n\nhigh-control neutral < chance:",
    pval(prop.test(high$neutral, high$total, 1/3, 'less')$p.value),
    "\n\nlow bad > high bad:",
    pval(prop.test(X$bad, X$total, alternative='greater')$p.value),
    "\n\nhigh good > low good:",
    pval(prop.test(X$good, X$total, alternative='less')$p.value)
)
```


# Regression "check" plot

```{r, fig.width=8, fig.height=4}
# BASELINE = mean(df$evaluation)

relu = function(x) {
    if_else(x < 0, 0, x)
}

p1 = df %>% 
    ggplot(aes(evaluation, as.numeric(considered), color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    stat_smooth(geom="line", size=0.8, linetype = "dotted", alpha=0.5) +
    # geom_smooth(se=F, method=lm, formula=y ~ x + abs(x), alpha=0.1) +
    geom_smooth(se=F, method=glm, 
        formula=y ~ relu(x) + abs(x),
        method.args = list(family = "binomial"),
        alpha=0.1) +
    ylab("consideration probability") +
    control_colors

p2 = df %>% 
    ggplot(aes(evaluation, considered - accessibility, color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    stat_smooth(geom="line", size=0.8, linetype = "dotted", alpha=0.5) +
    geom_smooth(se=F, method=lm, formula=y ~ abs(x) + relu(x), alpha=0.1) +
    # geom_smooth(se=F, method=lm, formula=y ~ exp(0.2*x) + abs(x), alpha=0.1) +
    ylab("relative consideration probability") +
    control_colors

p1 + p2 + plot_layout(guides = "collect")
```

# Value distributions

Gray is the accessibility data. Blue and yellow are outcomes considered by each group.

```{r, fig.width=7.5, fig.height=4.5}
wrap_scenario = list(
    facet_wrap(~scenario, dir="v", ncol=4),
    theme(strip.text.x = element_text(size=12), legend.position="top")
)

baselines = df %>%
    group_by(scenario, evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    group_by(scenario) %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, scenario, evaluation) %>% 
    group_by(control, scenario) %>% 
    mutate(prop=n/sum(n)) %>% 
    ggplot(aes(evaluation, prop)) + 
        geom_bar(data=baselines, stat="identity", alpha=1, fill="gray50", position="identity") +
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, position="identity") +
        control_colors + wrap_scenario + 
        labs(fill="considered by", y="proportion")
```

```{r, fig.width=7.5}
baselines = df %>%
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, evaluation) %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    ggplot(aes(evaluation, prop)) + 
        geom_bar(data=baselines, stat="identity", alpha=1, fill="gray50", position="identity") +
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, position="identity") +
        control_colors + facet_wrap(~control) +
        labs(fill="considered by", y="proportion") + 
        theme(legend.position="none")
```

## Relative proportions

New plot: this is like the above but subtracting out the accessibility value. It
shows how much more frequent each value among considered outcomes than we would
expect from accessibility alone.

```{r, fig.width=7.5}
baselines = df %>%
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, evaluation) %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    left_join(transmute(baselines, evaluation, baseline=prop)) %>% 
    ggplot(aes(evaluation, prop-baseline)) + 
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, width=.7, position="dodge") +
        control_colors +
        labs(y="relative proportion")
```

# Modeling

## Model comparison

- loo is an estimate of predictive likelihood; it will be close to AIC / -2.
- d_loo is the difference in loo from the best model
- dse is the standard error of that difference
- weight "can be loosely interpreted as the probability of each model
  (among the compared model) given the data"

```{r}
read_csv("../model/results/comparison.csv") %>% 
    select(name, loo, d_loo, dse, weight) %>% 
    mutate(across(-name, signif, 4)) %>% 
    kable
```

I'm not exactly sure how to interpret the dse, but the most obvious
interpretation to me is that it could have easily come out the other
direction.

## Difference in β

```{r}
chain = read_csv('../model/results/chain.csv')

chain %>% 
    select(β_low, β_high) %>% 
    pivot_longer(c(β_low, β_high), names_to="param", values_to="value", names_prefix="") %>% 
    mutate(param = factor(param, levels=c("β_low", "β_high"))) %>% 
    ggplot(aes(value, fill=param, color=param)) +
    geom_density(alpha=0.2) + control_colors

p_higher = mean(chain$β_high > chain$β_low)
```

It looks like they overlap a lot, but this is (likely) because they both
correlate with the $C_{\text{exp}}$ parameter. If we compare them, 
$\beta_{\text{high}}$ is higher `r 100*p_higher`% of the time.

## Posterior predictive checks

Here we are recreating plots using simulations from the joint model.

```{r}
ppc = read_csv("../model/results/ppc.csv") %>% 
    pivot_longer(c(low, high), names_to="control", values_to="n", names_prefix="") %>% 
    mutate(control = factor(control, levels=c("low", "high")))

ppc %>% 
    left_join(ebins) %>% 
    group_by(control,ebin) %>% 
    summarise(n=sum(n)) %>% 
    group_by(control) %>%
    mutate(prop = n / sum(n)) %>% 
    ggplot(aes(ebin, y=prop, group=control,fill=control)) + 
    geom_bar(position="dodge", stat="identity", alpha=0.7) +
    geom_hline(yintercept=1/3, linetype="solid") +
    control_colors +
    labs(x="value bin", y="proportion of considered outcomes")
```

```{r, fig.width=7.5}
ppc %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    left_join(transmute(baselines, evaluation, baseline=prop)) %>% 
    ggplot(aes(evaluation, prop-baseline)) + 
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, width=.7, position="dodge") +
        control_colors +
        labs(y="relative proportion")
```

# What went wrong?


```{r}
pdf

full_consideration %>% 
    filter(scenario != "practice") %>% 
    group_by(scenario) %>% 
    summarise(mean(outcome == "UNK"))

full_consideration %>% 
    filter(scenario != "practice") %>% 
    filter(outcome == "UNK") %>% print(n=100)
```


```{r}
read_csv("/Users/fred/Downloads/prolific_export_61cc9e46a7364db7a025cca8.csv") %>% 
    filter(status == "APPROVED") %>%
    select(completed_datetiem)
    summarise(mean(time_taken))


read_csv("/Users/fred/Downloads/prolific_export_61e9fb5a18392098af41d698.csv") %>% 
    filter(status == "AWAITING REVIEW") %>%
    summarise(mean(time_taken))

```
