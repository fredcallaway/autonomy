---
title: Genie Game Results â€” First Considered (v2.0)
date: "`r Sys.Date()`"
author: "fredcallaway"
output:
  rmdformats::robobook:
    code_folding: hide
    self_contained: true
---


```{r setup, include=FALSE}
source("base.r")
library(moments)
library(scales)
library(infer)

VERSIONS = c('v2.0')
load_data = function(type) {
    VERSIONS %>% 
    map(~ read_csv(glue('../data/{.x}/{type}.csv'), col_types = cols())) %>% 
    bind_rows
}

considered_colors = scale_colour_manual(values=c(
    "#3DD93D",
    "#666666"
), aesthetics=c("fill", "colour"), name="")

control_colors = scale_colour_manual(values=c(
    "#31ADF4",
    "#F5CE47"
), aesthetics=c("fill", "colour"))
```

# Exclusions

```{r load_data}
full_pdf = load_data('participants') %>% 
    filter(completed) %>% 
    # filter(wid != "w963f6eb")  %>%  # not actually completed, not sure what's going on
    select(-c(consideration_time, reflection_time, n_considered, n_unconsidered, version, bonus, completed)) %>%
    mutate(
        obligatory_check = factor(if_else(comp_radio, 'incorrect', 'correct', 'empty'),
                                  levels=c('empty', 'incorrect', 'correct')),
        # ignored_comprehension = obligatory_check == "empty" & is.na(comp_free)
    )

full_df = load_data('outcomes') %>% 
    rename(scenario = prompt_id) %>% 
    mutate(scenario = tolower(scenario))

full_scenarios = load_data('scenarios') %>% 
    rename(scenario = prompt_id) %>% 
    mutate(scenario = tolower(scenario))

full_slider = load_data('slider_check')

slider_check = full_slider %>% 
    mutate(prompt = word(prompt)) %>% 
    pivot_wider(names_from=prompt, values_from=response) %>% 
    mutate(
        p1 = Breaking < Stubbing,
        p2 = Stubbing < Finding,
        p3 = Finding < Winning,
        pass = p1 & p2 & p3
    )

slider_check %>% summarise(across(-wid, mean))
slider_check %>% filter(!p3)

# table(full_pdf$obligatory_check)
pdf = full_pdf %>% 
    filter(obligatory_check == "correct") %>% 
    left_join(slider_check) %>% 
    # filter(pass) %>% 
    mutate(
        subj = row_number(),
        control = factor(control, levels=c("low", "high"))
    )

pdf2 = select(pdf, wid, subj, control)

scenarios = full_scenarios %>%
    right_join(pdf2)  %>% 
    filter(scenario != "practice") %>%
    filter(considered %nin% c("NONE", "UNK")) %>% 
    group_by(wid) %>% 
    mutate(
        scenario_evaluation_z = zscore(scenario_evaluation),
        trial_number = row_number(),
    ) %>% 
    ungroup()
    
df = full_df %>% 
    filter(raw_outcome != "ape") %>% 
    right_join(pdf2) %>%  # also drops excluded participants
    right_join(select(scenarios, wid, scenario, considered, 
                      scenario_evaluation, scenario_evaluation_z)) %>%  # drops UNK and NONE trials
    mutate(
        considered = outcome==considered,
        consideration = if_else(considered, "considered", "unconsidered")
    ) %>% 
    group_by(wid) %>% 
    mutate(
        evaluation_z = zscore(evaluation),
        abs_eval = abs(evaluation),
        abs_eval_z = zscore(abs_eval),
    ) %>% 
    ungroup()

# n_drop = nrow(full_pdf) - nrow(pdf)
# n_drop_unk = nrow(unk_df) - nrow(df)
# n_trial = nrow(df)

df = left_join(df, select(scenarios, wid, scenario, scenario_evaluation, scenario_evaluation_z))
acc = read_csv('../data/acc-v2.0/accessibility.csv', col_types = cols())

acc %>% 
    filter(cat_id != "EUROCITIES") %>%
    filter(outcome != "UNK") %>%
    count(outcome) %>% 
    mutate(accessibility = n / length(unique(acc$wid))) %>% 
    select(-n) %>% 
    right_join(df) -> df

stopifnot(df %>% group_by(wid, scenario) %>% filter(sum(considered)!=1) %>% nrow == 0)
stopifnot(df %>% filter(is.na(accessibility)) %>% nrow == 0)

df %>% write_csv("../data/processed.csv")
```

- `r nrow(full_pdf)` participants recruited.
- `r sum(full_pdf$obligatory_check != "correct")` fail the comprehension check.
<!-- - `r sum(slider_check$pass == FALSE)` participants fail the slider check -->
- `r nrow(pdf)` participants remain.


# Consideration probability by outcome value

How does the probability of an item being included in the considered set
depend on its value (measured by post-decision rating)?

```{r, fig.width=8, fig.height=4, cache=T, cache=T, dependson=load_data}
# BASELINE = mean(df$evaluation)

relu = function(x) {
    if_else(x < 0, 0, x)
}

p1 = df %>% 
    ggplot(aes(evaluation, as.numeric(considered), color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    stat_smooth(geom="line", size=0.8, linetype = "dotted", alpha=0.5) +
    # geom_smooth(se=F, method=lm, formula=y ~ x + abs(x), alpha=0.1) +
    geom_smooth(se=F, method=glm, 
        formula=y ~ relu(x) + abs(x),
        method.args = list(family = "binomial"),
        alpha=0.1) +
    ylab("consideration probability") +
    control_colors

p2 = df %>% 
    ggplot(aes(evaluation, considered - accessibility, color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    stat_smooth(geom="line", size=0.8, linetype = "dotted", alpha=0.5) +
    geom_smooth(se=F, method=lm, formula=y ~ abs(x) + relu(x), alpha=0.1) +
    # geom_smooth(se=F, method=lm, formula=y ~ exp(0.2*x) + abs(x), alpha=0.1) +
    ylab("relative consideration probability") +
    control_colors

p1 + p2 + plot_layout(guides = "collect")
```

Reading the plot: points show binned means with 95% CI error bars. The dashed
line shows a non-parameteric [GAM](https://en.wikipedia.org/wiki/Generalized_additive_model)
fit. The solid line shows a logistic regression of the form
$\text{logit}(y) = \beta_0 + \beta_1 x + \beta_2 |x|$. This is an adaptation
of the earlier apples/oranges version of our model.


## Stats

Chisquare test on proportion considered outcomes above 0
```{r}
df %>% 
    filter(considered) %>% 
    mutate(good=evaluation > 0) %>% 
    chisq_test(good ~ control) %>% kable(digits=3)
```

t-test on value of considered outcomes
```{r}
df %>% 
    filter(considered) %>% 
    group_by(control) %>% 
    t_test(evaluation ~ control, order=c("high", "low")) %>% kable(digits=3)
```

Mixed-effects logistic regression. Note that I've replaced signed value
with a relu (that is max(0, value)) in order to prevent the absolute
value term from being used to flatten out the left side of signed value.
This is just a reparameritization, but it does affect statistical
significance.

```{r, fig.height=2, cache=T, dependson=load_data}
consideration_model = df %>% 
    mutate(
        accessibility = zscore(accessibility), 
        evaluation = zscore(evaluation),
        control_high = 1*(control == "high"),
        control_low = 1*(control == "low"),

    ) %>% 
    glmer(considered ~ accessibility + relu(evaluation) + abs(evaluation) +
        control_low : abs(evaluation) + control_high : relu(evaluation) +
        (accessibility + relu(evaluation) + abs(evaluation) | wid),
     family=binomial, data=.)

plot_coefs(consideration_model, omit.coefs=c("controlhigh", "(Intercept)"), colors="black") #plot
summ(consideration_model)
```

## By scenario 

We have eight scenarios, two for each category.

- **sports (season)**: Pick a professional sport and you'll get a free pair of front-row tickets every week for one season. You have to go every week (and you can't sell them!)
- **sports (silence)**: Pick a professional sport and you'll never see or hear about it again in your life.
- **animals (intimate)**: Pick a zoo animal and you'll spend 20 minutes in a cage with it.
- **animals (bubble)**: Pick a zoo animal and you'll get to watch it in its natural habitat from a magical floating bubble for a few hours.
- **subjects (school)**: Pick an academic subject and you'll have to pass the entry level course in that subject at a community college.
- **subjects (magic)**: Pick an academic subject and you'll instantly gain the knowledge of a typical PhD in that subject.
- **vehicles (commute)**: Pick a mode of transportation and you'll have to take it to work for the next year (it'll be free!)
- **vehicles (veto)**: Pick a mode of transportation and you won't be allowed to use it for the next year.

Here is the "check plot" for each:

```{r, fig.width=7.5, fig.height=5}

wrap_scenario = list(
    facet_wrap(~scenario, dir="v", ncol=4),
    theme(strip.text.x = element_text(size=12), legend.position="top")
)

df %>% 
    ggplot(aes(evaluation, as.numeric(considered) - accessibility, color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    geom_smooth(se=F, method=lm, 
        formula=y ~ abs(x) + relu(x),
        method.args = list(family = "binomial"),
        alpha=0.1) +
    ylab("relative consideration probability") +
    control_colors + wrap_scenario
```

These all look terrible.


# Value distributions

To better understand the effect of scenario, we need to look at the underlying
distributions of outcome values. Here we are plotting the distribution of all
outcome values in gray (weighted by accessibility) and the distribution of
considered outcomes in blue and yellow.

```{r, fig.width=7.5, fig.height=4.5, cache=T}
baselines = df %>%
    group_by(scenario, evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    group_by(scenario) %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, scenario, evaluation) %>% 
    group_by(control, scenario) %>% 
    mutate(prop=n/sum(n)) %>% 
    ggplot(aes(evaluation, prop)) + 
        geom_bar(data=baselines, stat="identity", alpha=1, fill="gray50", position="identity") +
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, position="identity") +
        control_colors + wrap_scenario + 
        labs(fill="considered by", y="proportion")
```

Plotted this way, it actually looks like the effect is somewhat more consistent.
However, it also just looks really noisy. Looking at this distribution plot
collapsing across scenarios, we see that the effect is really driven by the
probability of considering the most extreme-valued outcomes.

```{r}
baselines = df %>%
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, evaluation) %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    ggplot(aes(evaluation, prop)) + 
        geom_bar(data=baselines, stat="identity", alpha=1, fill="gray50", position="identity") +
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, position="identity") +
        control_colors +
        labs(fill="considered by", y="proportion")

# full_scenarios %>% filter(scenario != "practice") %>%  filter(considered=="UNK")
```

```{r}
X = baselines %>% 
    mutate(ebin=cut(cumsum(prop), c(0, 1/3, 2/3, 1.01), labels=c("bad", "neutral", "good"))) %>% 
    select(evaluation, ebin) %>% 
    right_join(df) %>% 
    filter(considered)

baselines = df %>%
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

X %>% 
    filter(control=="low") %>% 
    mutate(x=ebin=="neutral") %>% 
    prop_test(x ~ NULL, p=1/3, alternative='less', success='TRUE')

X %>% 
    filter(control=="high") %>% 
    mutate(x=ebin=="good") %>% 
    prop_test(x ~ NULL, p=1/3, alternative='greater', success='TRUE')

X %>% 
    mutate(x=ebin=="bad") %>% 
    prop_test(x ~ control, success='TRUE', order=c('low', 'high'), alternative='greater')
```
