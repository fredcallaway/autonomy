---
title: Genie Game Results — Followup
date: "`r Sys.Date()`"
author: "fredcallaway"
output:
  rmdformats::robobook:
    code_folding: hide
    self_contained: true
---

Here we are showing results with the ...

```{r setup, include=FALSE}
source("base.r")
library(moments)
library(scales)
library(infer)

# VERSIONS = c('v4.0', 'v4.0B')
VERSIONS = c('v3.1')

load_data = function(type) {
    VERSIONS %>% 
    map(~ 
        read_csv(glue('../data/{.x}/{type}.csv'), col_types = cols()) %>% 
        mutate(version = .x)
     ) %>% 
    bind_rows
}

considered_colors = scale_colour_manual(values=c(
    "#3DD93D",
    "#666666"
), aesthetics=c("fill", "colour"), name="")

control_colors = scale_colour_manual(values=c(
    "#31ADF4",
    "#F5CE47"
), aesthetics=c("fill", "colour"))

wrap_scenario = list(
    facet_wrap(~scenario, dir="v", ncol=4),
    theme(strip.text.x = element_text(size=12), legend.position="top")
)
```

# Exclusions

```{r load_data}
full_pdf = load_data('participants') %>% 
    filter(completed) %>% 
    select(-c(consideration_time, reflection_time, n_considered, n_unconsidered, version, bonus, completed)) %>%
    mutate(
        obligatory_check = factor(if_else(comp_radio, 'incorrect', 'correct', 'empty'),
                                  levels=c('empty', 'incorrect', 'correct')),
    )

full_df = load_data('evaluation') %>% 
    rename(scenario = prompt_id) %>% 
    mutate(scenario = tolower(scenario))

full_consideration = load_data('consideration') %>% 
    rename(scenario = prompt_id) %>% 
    mutate(scenario = tolower(scenario))

full_slider = load_data('slider_check')

slider_check = full_slider %>% 
    mutate(prompt = word(prompt)) %>% 
    pivot_wider(names_from=prompt, values_from=response) %>% 
    mutate(
        p1 = Breaking < Stubbing,
        p2 = Stubbing < Finding,
        p3 = Finding < Winning,
        pass = p1 & p2 & p3
    )

# slider_check %>% summarise(across(-wid, mean))

# table(full_pdf$obligatory_check)
pdf = full_pdf %>% 
    filter(obligatory_check == "correct") %>% 
    left_join(slider_check) %>% 
    filter(pass) %>%
    mutate(
        control = factor(control, levels=c("low", "high"))
    )

pdf2 = select(pdf, wid, control)

consideration = full_consideration %>%
    right_join(pdf2)  %>% 
    filter(scenario != "practice") %>%
    filter(outcome %nin% c("NONE", "UNK")) %>%
    group_by(wid, scenario)  %>% 
    distinct(outcome) %>%   # EXCLUSION
    mutate(order = row_number())

df = full_df %>% 
    right_join(pdf2) %>% 
    filter(scenario != "practice") %>% 
    left_join(transmute(consideration, wid, scenario, outcome, order, considered=T)) %>% 
    replace_na(list(considered=F)) %>% 
    group_by(wid) %>% 
    mutate(
        evaluation_z = zscore(evaluation),
        abs_eval = abs(evaluation),
        abs_eval_z = zscore(abs_eval),
    ) %>% 
    ungroup()

raw_acc = read_csv('../data/acc-v2.0/accessibility.csv', col_types = cols())

# accessibility is the proportion of participants who listed each outcome
# when prompted with its category
accessibility = raw_acc %>% 
    filter(cat_id != "EUROCITIES") %>%
    filter(outcome != "UNK") %>%
    count(cat_id,outcome) %>% 
    mutate(accessibility = n / length(unique(raw_acc$wid))) %>% 
    select(-n)

df = left_join(df, accessibility) %>% 
    filter(!is.na(accessibility))
    # replace_na(list(accessibility=0))
# stopifnot(df %>% group_by(wid, scenario) %>% filter(sum(considered)!=1) %>% nrow == 0)

stopifnot(
    full_df %>% 
    filter(scenario != "practice" & outcome == "UNK") %>% 
    nrow == 0
)

df = df %>% 
    arrange(wid, scenario, order) %>% 
    group_by(wid, scenario) %>% 
    mutate(trial_id= cur_group_id()) %>% 
    ungroup()

df %>% write_csv("../data/processed.csv")
```

- `r nrow(full_pdf)` participants recruited.
- `r sum(full_pdf$obligatory_check != "correct")` failed the comprehension check.
- `r sum(!slider_check$pass)` participants failed the slider check.
- `r nrow(pdf)` passed both checks and are included in the analysis.


```{r}
old_outcomes = str_split('soccer, basketball, tennis, baseball, golf, volleyball, badminton, boxing, cricket, rugby, football, bowling, elephant, koala, lemur, sloth, giraffe, monkey, rhinoceros, deer, panda, peacock, tiger, lion, jaguar, zebra, gorilla, cobra, crocodile, kangaroo, english, history, french, spanish, physics, chemistry, biology, algebra, geometry, calculus, bicycle, unicycle, scooter, skateboard, car, limousine, helicopter, airplane, train, bus, boat', ', ', simplify=T)

length(old_outcomes)
# df = df %>% filter(outcome %in% old_outcomes)

full_pdf %>% nrow
```


```{r}
full_consideration %>% 
    filter(startsWith(scenario, "subjects")) %>% 
    with(mean(outcome == "UNK"))

full_consideration %>% 
    group_by(scenario) %>% 
    summarise(mean(outcome == "UNK"))
```

# Proportion of good/bad/neutral

```{r}
ebins = df %>% 
    group_by(evaluation) %>% 
    filter(!is.na(accessibility)) %>% 
    summarise(acc=sum(accessibility)) %>% 
    mutate(prop=acc/sum(acc)) %>% 
    mutate(ebin=cut(cumsum(prop), c(0, 1/3, 2/3, 1.01), labels=c("bad", "neutral", "good"))) %>% 
    select(evaluation, ebin)

df %>% 
    left_join(ebins) %>% 
    filter(considered) %>% 
    ggplot(aes(ebin, y=..prop.., group=control,fill=control)) + 
    geom_bar(position="dodge", alpha=0.7) +
    geom_hline(yintercept=1/3, linetype="solid") +
    control_colors +
    labs(x="value bin", y="proportion of considered outcomes")
```

```{r}

```

OK, so we definitely have a much stronger manipulation effect; that's great.
But the low-control group appears to be selectively considering *bad* outcomes,
rather than extreme outcomes. This is especially puzzling given the last
set of results, where people in both conditions selectively considered good outcomes.

This is bizarre.

## Tests

```{r}
baselines = df %>%
    filter(!is.na(accessibility)) %>% 
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

X = baselines %>% 
    mutate(ebin=cut(cumsum(prop), c(0, 1/3, 2/3, 1.01), labels=c("bad", "neutral", "good"))) %>% 
    select(evaluation, ebin) %>% 
    right_join(df) %>% 
    filter(considered) %>%
    count(control, ebin) %>% 
    pivot_wider(names_from=ebin, values_from=n) %>%
    mutate(total=bad+neutral+good)

low =  X %>% filter(control=="low")
high = X %>% filter(control=="high")

cat(
    "\n\nlow-control good > chance:",
    pval(prop.test(low$good, low$total, 1/3, 'greater')$p.value),
    "\n\nlow-control bad > chance:",
    pval(prop.test(low$bad, low$total, 1/3, 'greater')$p.value),
    "\n\nlow-control neutral < chance:",
    pval(prop.test(low$neutral, low$total, 1/3, 'less')$p.value),
    "\n\nhigh-control good > chance:",
    pval(prop.test(high$good, high$total, 1/3, 'greater')$p.value),
    "\n\nhigh-control bad > chance:",
    pval(prop.test(high$bad, high$total, 1/3, 'less')$p.value),
    "\n\nhigh-control neutral < chance:",
    pval(prop.test(high$neutral, high$total, 1/3, 'less')$p.value),
    "\n\nlow bad > high bad:",
    pval(prop.test(X$bad, X$total, alternative='greater')$p.value),
    "\n\nhigh good > low good:",
    pval(prop.test(X$good, X$total, alternative='less')$p.value)
)

prop.test(c(low$good, low$bad))
```


# Regression "check" plot

```{r, fig.width=8, fig.height=4}
# BASELINE = mean(df$evaluation)

relu = function(x) {
    if_else(x < 0, 0, x)
}
p1 = df %>% 
    mutate(considered_first = as.numeric(considered & order==1)) %>% 
    ggplot(aes(evaluation, considered_first, color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    stat_smooth(geom="line", size=0.8, linetype = "dotted", alpha=0.5) +
    # geom_smooth(se=F, method=lm, formula=y ~ x + abs(x), alpha=0.1) +
    geom_smooth(se=F, method=glm, 
        formula=y ~ relu(x) + abs(x),
        method.args = list(family = "binomial"),
        alpha=0.1) +
    ylab("consideration probability") +
    control_colors

p2 = df %>% 
    ggplot(aes(evaluation, considered - accessibility, color=control)) +
    stat_summary_bin(fun.data=mean_cl_boot, bins=5, alpha=0.5, 
                     position=position_dodge(width=.5)) +
    stat_smooth(geom="line", size=0.8, linetype = "dotted", alpha=0.5) +
    geom_smooth(se=F, method=lm, formula=y ~ abs(x) + relu(x), alpha=0.1) +
    # geom_smooth(se=F, method=lm, formula=y ~ exp(0.2*x) + abs(x), alpha=0.1) +
    ylab("relative consideration probability") +
    control_colors

p1 + p2 + plot_layout(guides = "collect")
```

```{r, fig.height=2, cache=T, dependson=load_data}
consideration_model = df %>% 
    mutate(
        accessibility = zscore(accessibility), 
        evaluation = zscore(evaluation),
        control_high = 1*(control == "high"),
        control_low = 1*(control == "low"),

    ) %>% 
    glmer(considered ~ accessibility + relu(evaluation) + abs(evaluation) +
        control_low : abs(evaluation) + control_high : relu(evaluation) +
        (accessibility + relu(evaluation) + abs(evaluation) | wid),
     family=binomial, data=.)

plot_coefs(consideration_model, omit.coefs=c("controlhigh", "(Intercept)"), colors="black") #plot
summ(consideration_model)
```


```{r}
model = df %>% 
    filter(control == "low") %>% 
    mutate(
        accessibility = zscore(accessibility), 
        evaluation = zscore(evaluation),
    ) %>% 
    glmer(considered ~ accessibility + evaluation + abs(evaluation) +
        (evaluation + abs(evaluation) | wid),
     family=binomial, data=.)

summ(model)
```

```{r}
model = df %>% 
    filter(control == "low") %>% 
    mutate(
        accessibility = zscore(accessibility), 
        evaluation = zscore(evaluation),
    ) %>% 
    lmer(considered-accessibility ~ evaluation + abs(evaluation) +
        (evaluation + abs(evaluation) | wid),
    data=.)

summ(model)
```

# Value distributions

Gray is the accessibility data. Blue and yellow are outcomes considered by each group.

```{r, fig.width=7.5, fig.height=4.5}

df %>% filter(considered & (control == "low") & (scenario == "animals (bubble)"))
df %>% filter(considered & (control == "low") & (scenario == "subjects (magic)"))

baselines = df %>%
    group_by(scenario, evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    group_by(scenario) %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, scenario, evaluation) %>% 
    group_by(control, scenario) %>% 
    mutate(prop=n/sum(n)) %>% 
    ggplot(aes(evaluation, prop)) + 
        geom_bar(data=baselines, stat="identity", alpha=1, fill="gray50", position="identity") +
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, position="identity") +
        control_colors + wrap_scenario + 
        labs(fill="considered by", y="proportion")
```

```{r, fig.width=7.5}
baselines = df %>%
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, evaluation) %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    ggplot(aes(evaluation, prop)) + 
        geom_bar(data=baselines, stat="identity", alpha=1, fill="gray50", position="identity") +
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, position="identity") +
        control_colors + facet_wrap(~control) +
        labs(fill="considered by", y="proportion") + 
        theme(legend.position="none")
```

## Relative proportions

New plot: this is like the above but subtracting out the accessibility value. It
shows how much more frequent each value among considered outcomes than we would
expect from accessibility alone.

```{r, fig.width=7.5}
baselines = df %>%
    group_by(evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, evaluation) %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    left_join(transmute(baselines, evaluation, baseline=prop)) %>% 
    ggplot(aes(evaluation, prop-baseline)) + 
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, width=.7, position="dodge") +
        control_colors +
        labs(y="relative proportion")
```


```{r, fig.width=7.5}
baselines = df %>%
    group_by(scenario,evaluation) %>% 
    summarise(acc=sum(accessibility))  %>% 
    mutate(prop=acc/sum(acc))

df %>% 
    filter(considered) %>% 
    count(control, scenario, evaluation) %>% 
    group_by(control,scenario) %>% 
    mutate(prop=n/sum(n)) %>% 
    left_join(transmute(baselines, evaluation, baseline=prop)) %>% 
    ggplot(aes(evaluation, prop-baseline)) + 
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, width=.7, position="dodge") +
        control_colors + wrap_scenario +
        labs(y="relative proportion")
```

# Modeling

## Model comparison

- loo is an estimate of predictive likelihood; it will be close to AIC / -2.
- d_loo is the difference in loo from the best model
- dse is the standard error of that difference
- weight "can be loosely interpreted as the probability of each model
  (among the compared model) given the data"

```{r}
read_csv("../model/results/comparison.csv") %>% 
    select(name, loo, d_loo, dse, weight) %>% 
    mutate(across(-name, signif, 4)) %>% 
    kable
```

It looks like softmax alone (with different temperature by condition) performs best.
This actually makes sense, given the next plot.

## Difference in β

```{r}
chain = read_csv('../model/results/chain.csv')

chain %>% 
    select(β_low, β_high) %>% 
    pivot_longer(c(β_low, β_high), names_to="param", values_to="value", names_prefix="") %>% 
    mutate(param = factor(param, levels=c("β_low", "β_high"))) %>% 
    ggplot(aes(value, fill=param, color=param)) +
    geom_density(alpha=0.2) + control_colors

p_higher = mean(chain$β_high > chain$β_low)
```

The temperature is *negative* in the low control condition. This makes sense
because behaviorally, we see selective consideration of bad outcomes in that
condition.

## Posterior predictive checks

Here we are recreating plots using simulations from the joint model.

```{r}
ppc = read_csv("../model/results/ppc.csv") %>% 
    pivot_longer(c(low, high), names_to="control", values_to="n", names_prefix="") %>% 
    mutate(control = factor(control, levels=c("low", "high")))

ppc %>% 
    left_join(ebins) %>% 
    group_by(control,ebin) %>% 
    summarise(n=sum(n)) %>% 
    group_by(control) %>%
    mutate(prop = n / sum(n)) %>% 
    ggplot(aes(ebin, y=prop, group=control,fill=control)) + 
    geom_bar(position="dodge", stat="identity", alpha=0.7) +
    geom_hline(yintercept=1/3, linetype="solid") +
    control_colors +
    labs(x="value bin", y="proportion of considered outcomes")
```

That looks a lot like the data!

<!-- 
```{r, fig.width=7.5}
ppc %>% 
    group_by(control) %>% 
    mutate(prop=n/sum(n)) %>% 
    left_join(transmute(baselines, evaluation, baseline=prop)) %>% 
    ggplot(aes(evaluation, prop-baseline)) + 
        geom_bar(aes(fill=control), stat="identity", alpha=0.7, width=.7, position="dodge") +
        control_colors +
        labs(y="relative proportion")
```
-->